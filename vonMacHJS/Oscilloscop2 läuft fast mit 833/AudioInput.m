////  AudioInput.m//  Oscilloscop2////  Created by Heinz-Jšrg on 20.04.05.//  Copyright 2005 __MyCompanyName__. All rights reserved.////	Version 1.00: 30.04.2005		translated to X-Code 2#import  "MyLog.h"#import  "AudioInput.h"#include "CoreServices/CoreServices.h"NSLock         *audioBufferLock;@implementation AudioInput (Private)#ifdef NOT_USEDstatic double sineSweep() {    static double modulation = 0;    static double phase      = 0;    double result = sin(phase);    phase += 0.0078*(1+0.9*sin(modulation));    modulation += 0.0001;    return result;}static double trapezSweep() {    static double modulation = 0;    static double phase      = 0;        double result;    phase += 0.0078*(1+0.9*sin(modulation));    modulation += 0.0001;    if (sin(phase) > 0) {        result = 0.01+(.5*arc4random())/INT_MAX;    }    else {        result = -0.01-(0.5*arc4random())/INT_MAX;    }    return result;}#endif// this is the audio processing callback.OSStatus audioInputProc (                    AudioDeviceID           inDevice,                    const AudioTimeStamp   *inNow,                    const AudioBufferList  *inInputData,                    const AudioTimeStamp   *inInputTime,                    AudioBufferList        *outOutputData,                    const AudioTimeStamp   *inOutputTime,					void                   *dataPtr) {    AudioInput *self = (__bridge AudioInput *)dataPtr;    unsigned numChannels = self->deviceFormat.mChannelsPerFrame;    unsigned  bufferLength = self->deviceBufferSize * numChannels;    float	 *audioIn = inInputData->mBuffers[0].mData;	    // audioLength returns 2048, therefore we are copying in chunks of    // 2048s/44100 = 46.4 ms    // 2021-04-17: bufferLength returns 1064 ????, therefore we are copying    // in chunks of 512s/44100 = 11.6 ms        // kAudioTimeStampSampleTimeValid is valid    // kAudioTimeStampHostTimeValid   is valid    // kAudioTimeStampRateScalarValid is valid        [audioBufferLock lock];    for (int i = 0; i < bufferLength; i += numChannels) {        self->leftBuffer [self.inIndex] = audioIn[i+0];        self->rightBuffer[self.inIndex] = audioIn[i+1];        self.inIndex ++;        if (self.inIndex > self.bufferLength) {            self.inIndex = 0;        }    }        [audioBufferLock unlock];    return kAudioHardwareNoError;     }@end@implementation AudioInput- (AudioInput*)	init {	if (self = [super init]) {        /* class-specific initialization goes here */        audioBufferLock = [[NSLock alloc] init];    }    return		self;}- (AudioDeviceID) retrieveDefaultInputDevice:(AudioObjectPropertySelector) inOut {    UInt32          dataSize    = 0;    OSStatus        err         = 0;    AudioDeviceID   audioDeviceId;                                              // the default audio output device        AudioObjectPropertyAddress propertyAddress = {        inOut,        kAudioObjectPropertyScopeGlobal,        kAudioObjectPropertyElementMaster    };        /*!     @function   AudioObjectGetPropertyData     @abstract   Queries an AudioObject to get the data of the given                 property and places it in the provided buffer. Use this                 instead of deprecated AudioDeviceGetProperty.     @param      inObjectID                 The AudioObject to query.     @param      inAddress                 An AudioObjectPropertyAddress indicating which property                 is being queried.     @param      inQualifierDataSize                 A UInt32 indicating the size of the buffer pointed to by                 inQualifierData. Note that not all properties require                 qualification, in which case this value will be 0.     @param      inQualifierData,                 A buffer of data to be used in determining the data of the                 property being queried. Note that not all properties                 require qualification, in which case this value will be                 NULL.     @param      ioDataSize                 A UInt32 which on entry indicates the size of the buffer                 pointed to by outData and on exit indicates how much of the                 buffer was used.     @param      outData                 The buffer into which the AudioObject will put the data for                 the given property.     @result     An OSStatus indicating success or failure.     */        dataSize = sizeof(AudioDeviceID);    err = AudioObjectGetPropertyData(                kAudioObjectSystemObject,                &propertyAddress,                0,                NULL,                &dataSize,                &audioDeviceId    );        if (err != noErr) {        fprintf(stderr, "Could not get Default Input/Output Device");    }    return audioDeviceId;}- (UInt32) retrieveBufferSize:(AudioDeviceID) deviceId  {    UInt32          dataSize    = 0;    OSStatus        err         = 0;    UInt32          bufferSize;        AudioObjectPropertyAddress propertyAddress = {        kAudioDevicePropertyBufferFrameSize,        kAudioObjectPropertyScopeGlobal,        kAudioObjectPropertyElementMaster    };        dataSize = sizeof(bufferSize);        err = AudioObjectGetPropertyData(               deviceId,               &propertyAddress,               0,               NULL,               &dataSize,               (void *)&bufferSize          );        if (err != noErr ) {        fprintf(stderr, "get BufferSize error\n");    }    fprintf(stderr, "Buffersize: %ud\n", bufferSize);    return bufferSize;}- (OSStatus) retrieveDeviceInputFormat:(AudioDeviceID) deviceId                      description:(AudioStreamBasicDescription*) desc{    UInt32                      dataSize    = 0;    OSStatus                    err         = 0;        AudioObjectPropertyAddress propertyAddress = {        kAudioDevicePropertyStreamFormat,        kAudioObjectPropertyScopeInput,        kAudioObjectPropertyElementMaster    };        dataSize = sizeof(AudioStreamBasicDescription);        err = AudioObjectGetPropertyData(               deviceId,               &propertyAddress,               0,               NULL,               &dataSize,               (void *)desc          );        return err;}- (BOOL) hasOutput {    BOOL            result      = false;    UInt32          dataSize    = 0;    OSStatus        err         = 0;    /*     var address:AudioObjectPropertyAddress = AudioObjectPropertyAddress(     mSelector:AudioObjectPropertySelector(kAudioDevicePropertyStreamConfiguration),     mScope:AudioObjectPropertyScope(kAudioDevicePropertyScopeOutput),     mElement:0)          var propsize:UInt32 = UInt32(MemoryLayout<CFString?>.size);     var result:OSStatus = AudioObjectGetPropertyDataSize(self.audioDeviceID, &address, 0, nil, &propsize);     if (result != 0) {     return false;     }          let bufferList = UnsafeMutablePointer<AudioBufferList>.allocate(capacity:Int(propsize))     result = AudioObjectGetPropertyData(self.audioDeviceID, &address, 0, nil, &propsize, bufferList);     if (result != 0) {     return false     }          let buffers = UnsafeMutableAudioBufferListPointer(bufferList)     for bufferNum in 0..<buffers.count {     if buffers[bufferNum].mNumberChannels > 0 {     return true     }     }          return false     }     */    AudioObjectPropertyAddress property = {        kAudioDevicePropertyStreamConfiguration,        kAudioDevicePropertyScopeOutput,        kAudioObjectPropertyElementMaster    };    AudioBufferList *audioBufferList = NULL;    dataSize = sizeof(AudioBufferList);            err = AudioObjectGetPropertyData(              audioInputDeviceId,              &property,              0,              NULL,              &dataSize,              (void *)audioBufferList    );            return result;}- (void) storeRunLoop {    /* */        // This is a largely undocumented but absolutely necessary    // requirement starting with OS-X 10.6. If not called, queries and    // updates to various audio device properties are not handled    // correctly.    CFRunLoopRef theRunLoop = NULL;    AudioObjectPropertyAddress property = {        kAudioHardwarePropertyRunLoop,        kAudioObjectPropertyScopeGlobal,        kAudioObjectPropertyElementMaster    };    OSStatus result = AudioObjectSetPropertyData(                          kAudioObjectSystemObject,                          &property,                          0,                          NULL,                          sizeof(CFRunLoopRef),                          &theRunLoop                      );    if (result != noErr) {        NSLog(@"RtApiCore::RtApiCore: error setting run loop property!");    }        /* */}- (void) setupAudioLeft:(double *)leftChannel                  Right:(double *)rightChannel                   Size:(int)length{    OSStatus			err = kAudioHardwareNoError;        audioInputDeviceId	= kAudioDevicePropertyScopeInput;	     _initialized		= NO;       // get the default output device for the HAL    audioInputDeviceId = [self retrieveDefaultInputDevice:                                kAudioHardwarePropertyDefaultInputDevice                          ];        // get the buffersize that the default device uses for IO    deviceBufferSize = [self retrieveBufferSize:audioInputDeviceId];       // get a description of the data format used by the default device    err = [self retrieveDeviceInputFormat:audioInputDeviceId                              description:&deviceFormat           ];        if (err != kAudioHardwareNoError) {        fprintf(stderr, "get kAudioDevicePropertyStreamFormat "                        "error %d\n",(int) err);        return;    }        if (deviceFormat.mFormatID != kAudioFormatLinearPCM) {        fprintf(stderr, "mFormatID !=  kAudioFormatLinearPCM\n");        return;    }    if (!(deviceFormat.mFormatFlags & kLinearPCMFormatFlagIsFloat)) {        fprintf(stderr, "Sorry, currently only works with float "                        "format....\n");        return;    }    [self storeRunLoop];		_bufferLength	= length;	_inIndex		= 0;	leftBuffer		= leftChannel;	rightBuffer		= rightChannel;        _initialized		= YES;	        AudioDeviceIOProcID outIOProcID;                                            // No idea whats the purpose of this    err = AudioDeviceCreateIOProcID(                                            // Apple documentation sucks               audioInputDeviceId,               audioInputProc,               (__bridge void *)self,               &outIOProcID          );    if (err != kAudioHardwareNoError) {        fprintf(stderr, "Unable to install AudioDevice procedure....\n");        return;    }    /*     Properties of deviceFormat (taken from Apple docs)     mBitsPerChannel    The number of bits for one audio sample.     mBytesPerFrame     The number of bytes from the start of one frame to the                        start of the next frame in an audio buffer. Set this                        field to 0 for compressed formats.     mBytesPerPacket    The number of bytes in a packet of audio data. To                        indicate variable packet size, set this field to 0.                        For a format that uses variable packet size, specify                        the size of each packet using an                        AudioStreamPacketDescription structure.     mChannelsPerFrame  The number of channels in each frame of audio data.                        This value must be nonzero.     mFormatFlags       Format-specific flags to specify details of the                        format. Set to 0 to indicate no format flags.                        See Audio Data Format Identifiers for the flags                        that apply to each format.     mFormatID          An identifier specifying the general audio data                        format in the stream. See Audio Data Format                        Identifiers. This value must be nonzero.     mFramesPerPacket   The number of frames in a packet of audio data.                        For uncompressed audio, the value is 1. For                        variable bit-rate formats, the value is a larger                        fixed number, such as 1024 for AAC. For formats                        with a variable number of frames per packet, such                        as Ogg Vorbis, set this field to 0.     mReserved          Pads the structure out to force an even 8-byte                        alignment. Must be set to 0.     mSampleRate        The number of frames per second of the data in                        the stream, when the stream is played at normal                        speed. For compressed formats, this field indicates                        the number of frames per second of equivalent                        decompressed data.     */    fprintf(stderr, "mSampleRate = %g\n",      deviceFormat.mSampleRate);    fprintf(stderr, "mFormatFlags =%08XX\n",   deviceFormat.mFormatFlags);    fprintf(stderr, "mBytesPerPacket =%u\n",   deviceFormat.mBytesPerPacket);    fprintf(stderr, "mFramesPerPacket =%u\n",  deviceFormat.mFramesPerPacket);    fprintf(stderr, "mChannelsPerFrame =%u\n", deviceFormat.mChannelsPerFrame);    fprintf(stderr, "mBytesPerFrame =%u\n",    deviceFormat.mBytesPerFrame);    fprintf(stderr, "mBitsPerChannel =%u\n",   deviceFormat.mBitsPerChannel);}- (BOOL) start {    OSStatus					err = kAudioHardwareNoError;    if (!_initialized)   return false;    if (_soundRecording) return false;                err = AudioDeviceStart(audioInputDeviceId, audioInputProc);					// start recording sound through the device    if (err != kAudioHardwareNoError) return false;    _soundRecording = true;														// set the playing status global to true    return true;}- (BOOL) stop {    OSStatus 	err = kAudioHardwareNoError;        if (!_initialized)    return false;    if (!_soundRecording) return false;        err = AudioDeviceStop(audioInputDeviceId, audioInputProc);					// stop recording sound through the device        _soundRecording = false;													// set the playing status global to false    if (err != kAudioHardwareNoError) return false;    return true;}- (BOOL) isRunning {	return _soundRecording;}#pragma mark --- Clean up ---- (void) dealloc {    NSAssert(false, @"Never called! Why not?");    OSStatus 	err = kAudioHardwareNoError;	    err = AudioDeviceDestroyIOProcID(audioInputDeviceId, audioInputProc);		// remove the IO proc from the device    if (err != kAudioHardwareNoError) {    	fprintf(stderr, "Unable to remove AudioDevice procedure....\n");        return;    }    NSLog(@"dealloc called");	/////[super dealloc];} @end